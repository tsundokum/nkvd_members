{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "from yargy import Parser, rule, and_, or_\n",
    "from yargy.predicates import gram, is_capitalized, dictionary, in_, normalized, eq, caseless, type\n",
    "from yargy.interpretation import fact\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "CRAWLED_DATA = 'members2.jl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(CRAWLED_DATA) as f:\n",
    "    for line in f:\n",
    "        j = json.loads(line)\n",
    "        data.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "designation['position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 4s, sys: 152 ms, total: 5min 4s\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "info_columns = ['link', 'name', 'bio', 'party', 'nkvd', 'repr', 'info']\n",
    "designation_columns = 'marker preposition date position source unit'.split()\n",
    "parsed_designation_columns = ['parsed_designation', 'parsed_region']\n",
    "\n",
    "flattened = []\n",
    "for d in data:\n",
    "    info = {}\n",
    "    for c in info_columns:\n",
    "        info[c] = d[c]\n",
    "    for d in d['designations']:\n",
    "        designation = {}\n",
    "        for i, c in enumerate(designation_columns):\n",
    "            designation[c] = d[i]\n",
    "        designation_string = designation['position'] if designation['position'] else ''\n",
    "        p, r = parse(designation_string)\n",
    "        designation['parsed_designation'] = p\n",
    "        designation['parsed_region'] = r\n",
    "        flat_row = dict(info)\n",
    "        flat_row.update(designation)\n",
    "        flattened.append(flat_row)\n",
    "flattened = pd.DataFrame(flattened, columns=info_columns + designation_columns + parsed_designation_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened.to_csv('flattened.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to extract job description from the crawled data\n",
    "# table columns order: [marker, preposition, date, position, source, unit]\n",
    "\n",
    "f\n",
    "counter = Counter()\n",
    "texts = []\n",
    "with open(CRAWLED_DATA) as f:\n",
    "    for line in f:\n",
    "        j = json.loads(line)\n",
    "        for row in j['designations']:\n",
    "            p = row[3]\n",
    "            texts.append(p)\n",
    "            if p:\n",
    "                if not p.lower().startswith('уволен'):\n",
    "                    counter[p] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('positions.txt', 'w') as f:\n",
    "    for p in sorted(t for t in texts if t):\n",
    "        print(p, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['[сотр.] ОО НКВД 2 отдельной Краснознаменной армии',\n",
    " 'врио нач. УПВО НКВД Грузинской ССР',\n",
    " 'врио нач. спецтюрьмы ГУГБ НКВД СССР',\n",
    " 'делопроизводитель-машинистка ОКР СМЕРШ 10 фронтового управления оборонительного строительства',\n",
    " 'зам. министра внутренних дел УССР',\n",
    " 'зам. нач. 3 СО Астраханского ГО УНКВД Сталинградской обл.',\n",
    " 'зам. нач. 4 отдела УНКВД Харьковской обл.',\n",
    " 'зам. нач. Актюбинского ИТЛ',\n",
    " 'зам. нач. политотдела совхоза «Нарым» НКВД Узбекской ССР',\n",
    " 'инспектор УНКВД Ленинградской обл.',\n",
    " 'нач. Волховского РО УНКВД Ленинградской обл.',\n",
    " 'нач. Змеиногорского РО УНКВД Алтайского края',\n",
    " 'нач. Майнского РО УНКВД Куйбышевской обл.',\n",
    " 'нач. ОКР СМЕРШ 86 стрелковой дивизии',\n",
    " 'нач. ОО НКВД 227 авиадивизии',\n",
    " 'нач. Осьминского РО УНКВД Ленинградской обл.',\n",
    " 'нач. Спасского РО УНКВД Рязанской обл.',\n",
    " 'нач. Халтуринского РО УНКВД Кировской обл.',\n",
    " 'нач. оперпункта ст. Котовск ДТО НКВД Одесской железной дороги',\n",
    " 'нач. отделения ОИТК и ТП УНКВД Чкаловской обл.',\n",
    " 'нач. отделения ст. Куйбышевка-Восточная ДТО НКВД Амурской железной дороги',\n",
    " 'нач. охраны тыла 20 армии Западного фронта',\n",
    " 'нач. хозотделения 3 СО НКВД СССР',\n",
    " 'нач. штаба 159 полка УПВО НКВД УССР',\n",
    " 'нач. штаба ПВ НКВД Киевского округа',\n",
    " 'оперуполномоченный 4 отделения ОО НКВД ЗабВО',\n",
    " 'оперуполномоченный Балашовского РО УНКВД Саратовской обл.',\n",
    " 'оперуполномоченный Кодымского РО УГБ НКВД УССР',\n",
    " 'оперуполномоченный ОО НКВД Юго-Западного фронта',\n",
    " 'оперуполномоченный ст. Куйбышевка ДТО НКВД Амурской железной дороги',\n",
    " 'оперуполномоченный ст. Оренбург ДТО НКВД',\n",
    " 'оперуполномоченный управления коменданта Московского Кремля НКВД СССР',\n",
    " 'пом. нач. 3 отдела УНКВД Иркутской обл.',\n",
    " 'пом. нач. 6 отдела УГБ НКВД Татарской АССР',\n",
    " 'пом. нач. ОКР СМЕРШ 19 стрелкового корпуса',\n",
    " 'пом. нач. Херсонского ГО УНКВД Николаевской обл. УССР',\n",
    " 'пом. нач. отделения ст. Медведево ДТО НКВД Калининской железной дороги',\n",
    " 'пом. нач. секретариата НКВД СССР',\n",
    " 'пом. оперуполномоченного Муслюмовского РО УГБ НКВД Татарской АССР',\n",
    " 'пом. оперуполномоченного ОО НКВД 13 казачьей кавалерийской дивизии УНКВД Азово-Черноморского края',\n",
    " 'пом. оперуполномоченного УНКВД Актюбинской обл. Казахской ССР',\n",
    " 'председатель отдела Военного трибунала УПВО НКВД по Донецкой обл.',\n",
    " 'сотр. ОКР СМЕРШ 57 армии',\n",
    " 'сотр. ТО НКВД Западной железной дороги',\n",
    " 'сотрудник НКВД УССР',\n",
    " 'сотрудник для особых поручений ОК НКВД СССР',\n",
    " 'сотрудник контрразведки',\n",
    " 'ст. оперуполномоченный 2 отделения ОО НКВД Юго-Западного фронта',\n",
    " 'ст. оперуполномоченный 4 отделения ОО НКВД Волховского фронта',\n",
    " 'ст. оперуполномоченный УНКВД Адыгейской АО',\n",
    " 'ст. пом. нач. Особой инспекции Союзной контрольной комиссии в Румынии']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Record = fact(\n",
    "    'Record',\n",
    "    ['position', 'unit', 'region']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOT = eq('.')\n",
    "\n",
    "# POSITION = rule(    \n",
    "#     eq('врид').optional(),\n",
    "#     or_(rule('пом', DOT.optional()),\n",
    "#         rule('зам', DOT.optional()),\n",
    "#         rule('ст', DOT.optional())).optional(),\n",
    "#     normalized('полковой').optional(),\n",
    "#     or_(\n",
    "#         rule(dictionary({'оперуполномоченный', 'сотрудник', 'командир', 'уполномоченный'})),\n",
    "#         rule(caseless('нач'), DOT)))\n",
    "\n",
    "# ############################################\n",
    "\n",
    "# CITY = rule(eq('г'), DOT.optional(), gram('NOUN'))\n",
    "# SSR = or_(rule(gram('ADJF'), \n",
    "#                or_(eq('ССР'), eq('АССР'), eq('АО'))),\n",
    "#           rule(or_(eq('БССР'), eq('УССР'))),\n",
    "#           rule(eq('СССР')))\n",
    "\n",
    "# KRAI = rule(gram('ADJF'), \n",
    "#             or_(rule(normalized('край')),\n",
    "#                 rule('обл', DOT.optional())))\n",
    "\n",
    "# OKRUG = rule(gram('ADJF'), normalized('округ'))\n",
    "\n",
    "# ARMY = rule(type('INT'), gram('ADJF').optional(), gram('ADJF').optional(), normalized('армия'))\n",
    "\n",
    "# FRONT = rule(gram('ADJF'), normalized('фронт'))\n",
    "\n",
    "# GUARD = rule(eq('гв'), DOT)\n",
    "# DIVISION = rule(type('INT'), GUARD.optional(), normalized('стрелковая').optional(), \n",
    "#                 or_(normalized('дивизия'),\n",
    "#                     normalized('авиадивизия'),\n",
    "#                     normalized('корпус')))\n",
    "\n",
    "# JD = or_(rule(eq('ж'), DOT, eq('д'), DOT),\n",
    "#          rule(normalized('железная'), normalized('дорога')))\n",
    "# RAILS = or_(rule(gram('ADJF'), JD),\n",
    "#             rule(JD, BY_NAME))\n",
    "\n",
    "# BY_NAME = rule(eq('им'), DOT, gram('NOUN'))\n",
    "\n",
    "# REGION = or_(\n",
    "#     CITY, SSR, KRAI, ARMY, DIVISION, RAILS, OKRUG, FRONT\n",
    "# )\n",
    "\n",
    "# #########################################\n",
    "\n",
    "# ST = rule(eq('ст'), DOT)\n",
    "# STATION = rule(ST, gram('NOUN'), eq('ДТО').optional(), eq('НКВД').optional())  \n",
    "# DEPARTMENT = rule(type('INT'), normalized('отдел'))\n",
    "\n",
    "# UNIT = or_(DEPARTMENT, STATION)\n",
    "\n",
    "# ##########################################\n",
    "\n",
    "# ## TODO fix code below\n",
    "# # RECORD = rule(\n",
    "# #     POSITION.interpretation(\n",
    "# #         Record.position\n",
    "# #     ),\n",
    "# #     UNIT.interpretation(\n",
    "# #         Record.unit\n",
    "# #     ),\n",
    "# #     REGION.interpretation(\n",
    "# #         Record.region\n",
    "# #     )\n",
    "# # ).interpretation(\n",
    "# #     Record\n",
    "# # )\n",
    "\n",
    "\n",
    "# pos_parser = Parser(POSITION)\n",
    "# unit_parser = Parser(UNIT)\n",
    "# region_parser = Parser(REGION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for d in data:\n",
    "#     print('>>>', d)\n",
    "#     for match in pos_parser.findall(d):\n",
    "#         b, e = match.tokens[0].span[0], match.tokens[-1].span[1]\n",
    "#         print(f'Position: {d[b:e]}')\n",
    "        \n",
    "#     for match in unit_parser.findall(d):\n",
    "#         b, e = match.tokens[0].span[0], match.tokens[-1].span[1]\n",
    "#         print(f'Unit: {d[b:e]}')\n",
    "       \n",
    "#     for match in region_parser.findall(d):\n",
    "#         b, e = match.tokens[0].span[0], match.tokens[-1].span[1]\n",
    "#         print(f'Region: {d[b:e]}')\n",
    "               \n",
    "# #     for match in parser.findall(d):\n",
    "# #         b, e = match.tokens[0].span[0], match.tokens[-1].span[1]\n",
    "# #         print(f'{(b, e)}: {d[:b]} [{d[b:e]}] {d[e+1:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOT = eq('.')\n",
    "\n",
    "POSITION = rule(    \n",
    "    or_(eq('врид'), \n",
    "        eq('врио')).optional(),\n",
    "    or_(rule('пом', DOT.optional()),\n",
    "        rule('зам', DOT.optional()),\n",
    "        rule('ст', DOT.optional()),\n",
    "        rule(dictionary({'заместитель'}))).optional(),\n",
    "    normalized('полковой').optional(),\n",
    "    or_(\n",
    "        rule('сотр', DOT.optional()),\n",
    "        rule(dictionary({'оперуполномоченный', 'сотрудник', 'командир', 'уполномоченный', 'шофер',\n",
    "                         'следователь', 'наркома', 'работник', 'инспектор', 'комендант', 'разведчик',\n",
    "                         'начальник', 'секретарь', 'особоуполномоченный', 'председатель', 'фельдъегерь',\n",
    "                         'сотрудница', 'лейтенант'\n",
    "                         })),\n",
    "        rule(caseless('нач'), DOT),\n",
    "        rule(normalized('министра'), 'внутренних', 'дел')\n",
    "    ),\n",
    "    or_(rule(eq('контрразведки')),\n",
    "        rule(eq('особой'), eq('роты'))).optional())\n",
    "\n",
    "pos_parser = Parser(POSITION)\n",
    "\n",
    "def parse(d):\n",
    "    for match in pos_parser.findall(d):\n",
    "        b, e = match.tokens[0].span[0], match.tokens[-1].span[1]\n",
    "        return  d[b:e],  d[e+1:]\n",
    "    return '', ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_parses = []\n",
    "\n",
    "for d, c in counter.most_common():\n",
    "    p, r = parse(d)\n",
    "    if p:\n",
    "        pass\n",
    "#         print(f'\\x1b[31m{p}\\x1b[0m \\x1b[34m{r}\\x1b[0m')\n",
    "    else:\n",
    "#         print(d)\n",
    "        failed_parses.append(d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(failed_parses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
